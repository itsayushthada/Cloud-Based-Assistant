{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Modules\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face Features Database\n",
    "face_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract faces from the Photos\n",
    "def face_extract(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if face is not ():\n",
    "        [x, y, w, h] = face[0]\n",
    "        face_image = gray[x:x+w , y:y+h]\n",
    "        return face_image, face[0]\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create your own Dataset at Runtime\n",
    "def dataset_maker(dataset_size = 100, dataset_location = \"./faces/ayush/\"):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        face, _ = face_extract(frame)\n",
    "        if face is not None:\n",
    "            face = cv2.resize(face, (300,300))\n",
    "            file_name = \"./faces/ayush/image\" + str(count) + \".jpg\"\n",
    "            cv2.imwrite(file_name, face)\n",
    "            \n",
    "            cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow(\"Dataset Preparation\", face)\n",
    "            count = count+1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or count >= dataset_size:\n",
    "                break\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Dataset made sucessefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model to Recognise the person or obkect in provided dataset.\n",
    "def model_training(dataset_location = \"./faces/ayush/\"):\n",
    "    onlyfiles = [file for file in listdir(dataset_location) if isfile(join(dataset_location, file))]\n",
    "    Training_Data, Labels = [], []\n",
    "    \n",
    "    for i, files in enumerate(onlyfiles):\n",
    "        image_path = dataset_location + onlyfiles[i]\n",
    "        images = cv2.imread(image_path, 0) # 0 means cv2.IMREAD_GRAYSCALE\n",
    "        Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "        Labels.append(i)\n",
    "\n",
    "    Labels = np.asarray(Labels, dtype=np.int32)\n",
    "    model = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "    model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "    print(\"Model trained sucessefully\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the possibility of the detected person in the detected\n",
    "def predict(model):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count, label, confidence = 0, 0, 0\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret == True:\n",
    "            face, coordinates = face_extract(img)\n",
    "            if coordinates is not None:\n",
    "                [x, y, w, h] = coordinates\n",
    "                cv2.resize(face, (300,300))\n",
    "                cv2.rectangle(img, (x,y), (x+h, y+w), (0,255,0), 2)\n",
    "                \n",
    "                if count == 0:\n",
    "                    label, confidence = model.predict(face)\n",
    "                    cv2.putText(img, \"Label: \"+str(label), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                    cv2.putText(img, \"Confidence: \"+str(confidence), (50,80), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                \n",
    "                count = count%60\n",
    "            cv2.imshow(\"Window\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maker(100)\n",
    "model = model_training()\n",
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
